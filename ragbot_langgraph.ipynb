{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30145a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a74b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagState(TypedDict):\n",
    "    question:str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a2fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name=\"llama3-70b-8192\")\n",
    "vectorstore = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a55c7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =[\n",
    "    \"Python is a programming language.\",\n",
    "    \"LangGraph helps build AI workflows.\",\n",
    "    \"RAG combines retrieval and generation.\",\n",
    "    \"Vector databases store embeddings.\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3551fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9e471c42-c469-4e64-ae41-5b3062055c0e',\n",
       " '491f8835-aae7-4ef1-9c01-c21ee7f636fd',\n",
       " '8adf1306-7cfa-4a7b-baaa-17854385081a',\n",
       " '0e0489c2-c0c8-4ade-aebc-d40a50bcc55a']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spillter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "split_docs = text_splitter.create_documents(docs)\n",
    "vectorstore.add_documents(split_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5406a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieval function\n",
    "def retrieve(state: RagState) -> RagState:\n",
    "    \"\"\"Generate  answer using retrieved docs\"\"\"\n",
    "    results = vectorstore.similarity_search(state[\"question\"], k=2)\n",
    "    return {\"documents\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c153e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: RagState) -> RagState:\n",
    "    \"\"\"Generate answer using retrieved docs\"\"\"\n",
    "    context = \"\\n\".join([doc.page_content for doc in state[\"documents\"]])\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {state['question']}\\nAnswer:\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f850fc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x21f4390ce90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(RagState)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cb70ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x21f4390ce90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91b2f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "965dc7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Python?\n",
      "Answer: A programming language.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    question = \"What is Python?\"\n",
    "    result = app.invoke({\"question\": question})\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {result['answer']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
